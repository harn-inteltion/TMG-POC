{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30a2ef8-df51-4452-9410-cb86f54a002c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/themallpocaws@inteltion.com/Data-Integration-Scenarios/00_common/common_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1876524-81ca-4dc2-8498-3bc6cd24bd23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read JSON file from S3 (use option(\"multiline\", \"true\") if your JSON is formatted across multiple lines)\n",
    "json_path = \"s3://tmg-poc-awsdb-apse1-stack-97db8-bucket/unity-catalog/catalog/poc_raw/forecast.json\"\n",
    "df_json = spark.read.option(\"multiline\", \"true\").json(json_path)\n",
    "display(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a34b8676-7d7c-4c2f-8b32-48b31e447102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "latitude = df_json.select(\"latitude\").first()[0]\n",
    "longitude = df_json.select(\"longitude\").first()[0]\n",
    "forecast_temp_unit = \"Celsius\"\n",
    "\n",
    "# Zip the two arrays (time and temperature) into one array of structs\n",
    "df_forecast = df_json.select(arrays_zip(\"hourly.time\", \"hourly.temperature_2m\").alias(\"forecast\"))\n",
    "# Explode the array so each row corresponds to one forecast entry\n",
    "df_forecast = df_forecast.select(explode(\"forecast\").alias(\"fc\"))\n",
    "\n",
    "# Build the DataFrame with the desired schema\n",
    "df = df_forecast.select(\n",
    "lit(latitude).alias(\"LATITUDE\"),\n",
    "lit(longitude).alias(\"LONGITUDE\"),\n",
    "to_date(col(\"fc.time\").substr(1, 10), \"yyyy-MM-dd\").alias(\"FORECAST_DATE\"),\n",
    "to_timestamp(col(\"fc.time\"), \"yyyy-MM-dd'T'HH:mm\").alias(\"FORECAST_TIME\"),\n",
    "col(\"fc.temperature_2m\").alias(\"FORECAST_TEMP\")\n",
    ").withColumn(\"FORECAST_TEMP_UNIT\", lit(forecast_temp_unit))\n",
    "\n",
    "# Cast columns as required\n",
    "df = df.withColumn(\"LATITUDE\", col(\"LATITUDE\").cast(DecimalType(12, 2))) \\\n",
    "    .withColumn(\"LONGITUDE\", col(\"LONGITUDE\").cast(DecimalType(12, 2))) \\\n",
    "    .withColumn(\"FORECAST_TEMP\", col(\"FORECAST_TEMP\").cast(DecimalType(12, 2)))\n",
    "# Write to Databricks SQL table\n",
    "# df.write.mode(\"overwrite\") \\\n",
    "# .saveAsTable(\"POC_STG.POC.FORECAST\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6483449960790549,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) INB_JSON_FORECAST",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
